# -*- coding: utf-8 -*-
"""BGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1evMmjjOBMh7ELTX3hikf4X9emn1jUOdj
"""

from __future__ import division, print_function
import os, sys, json
import warnings
warnings.warn = lambda *a, **kw: False

import numpy as np
import pandas as pd
from scipy.spatial import distance as dist
from scipy import stats
from sklearn import preprocessing, manifold, decomposition, random_projection, neighbors, metrics, linear_model
from sklearn.model_selection import cross_val_score

import tensorflow as tf


import matplotlib.pyplot as plt

# %matplotlib inline
import seaborn as sns
sns.set_style('whitegrid')
sns.set_context('talk', font_scale=1.2)
from IPython import display
np.random.seed(2018)
tf.set_random_seed(2018)

!unzip dev_test
f=open("dev.en")
contents = f.read()
print(contents)

import dev_test
data= dev_test

!pip install utils

!pip install bpemb
from bpemb import BPEmb

bpemb_en = BPEmb(lang="en", dim=100)
bpemb_hi = BPEmb(lang="hi", vs=1000)

bpemb_en.encode(contents)

from utils import *
from bigan import BiGAN
import dev_test

training_epochs = 50
batch_size = 128
display_step = 1
# learning_rate=0.001
learning_rate=0.0002
n_samples = int(dev_test.train)

training_epochs = 5000
batch_size = 128
display_step = 1
# learning_rate=0.001
learning_rate=0.0002

bigan = BiGAN(g_n_layers=[784, 500, 500, 20],
              d_n_layers=[1000, 1000, 1000],
              learning_rate=learning_rate,
              
             )

d_losses = []
accs = []
g_losses = []

for epoch in range(training_epochs):
    total_batch = int(1000/ batch_size)
    # Loop over all batches
    for i in range(total_batch):
        batch_xs, _ = mnist.train.next_batch(batch_size)
        # Fit training using batch data
        d_loss, acc, g_loss = bigan.partial_fit(batch_xs)
    # Display logs per epoch step
    if epoch % display_step == 0:
        print ("Epoch %d: D loss = %.4f, G loss = %.4f, D accuracy = %.4f "% (epoch+1, d_loss, g_loss, acc))
        
        d_losses.append(d_loss)
        accs.append(acc)
        g_losses.append(g_loss)

!mkdir -p trained_models/bigan_20

bigan.save('trained_models/bigan_20/')

x_gen = bigan.generate()
x_gen.shape

text ='The Sri Lankan team will play three ODI'

translator = bigan.BiGAN
 params['build_model'] = True
        gan = cls(**params)
        gan.generator = load_model(os.path.join(path, "generator.h5"))
        gan.discriminator = load_model(os.path.join(path, "discriminator.h5"))
        gan.encoder = load_model(os.path.join(path, "encoder.h5"))
        gan.bigan_generator = load_model(os.path.join(path, "bigan_generator.h5"))
for key, value in destination_language.items():
print(translator.output(text,dest = value).text)

import bleu

from bleu import BLEU

candidate, references = fetch_data(candidate,BGAN)
bleu = BLEU(candidate, BGAN.op)
print (bleu)
out = open('bleu_out.txt', 'w')
out.write(str(bleu))
out.close()

